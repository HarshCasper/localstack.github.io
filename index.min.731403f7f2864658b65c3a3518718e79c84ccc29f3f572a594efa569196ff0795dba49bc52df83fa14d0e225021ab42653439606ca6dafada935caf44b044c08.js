var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput'),referenceChildren,referenceCollapseBtn;if(userinput!=null){document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}}if(suggestions!=null){document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"/docs/getting-started/overview/",title:"Overview",description:"",content:'\u003ch2 id="what-is-localstack"\u003eWhat is LocalStack?\u003c/h2\u003e\n\u003cp\u003eLocalStack provides an easy-to-use test/mocking framework for developing Cloud applications.\nIt spins up a testing environment on your local machine that provides the same functionality and APIs as the real AWS cloud environment.\u003c/p\u003e\n\u003cp\u003eYou can run your Lambda functions, store data to DynamoDB tables, feed events through Kinesis streams, put your application behind an API Gateway, and much more. And all this happens on your local machine, without ever talking to the cloud.\u003c/p\u003e\n\u003ch2 id="documentation-resources"\u003eDocumentation resources\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRead the LocalStack \u003ca href="https://github.com/localstack/localstack/blob/master/README.md"\u003eREADME\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eGet started with the \u003ca href="../installation/"\u003eInstallation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:1,href:"/docs/getting-started/installation/",title:"Installation",description:"Installing and configuring LocalStack.",content:'\u003ch2 id="prerequisites"\u003ePrerequisites\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDocker\u003c/strong\u003e: The recommended way of installing LocalStack is using Docker\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePython\u003c/strong\u003e: Required to install the \u003ccode\u003elocalstack\u003c/code\u003e command-line interface (CLI)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="installation"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eThe easiest way to install LocalStack is via \u003ccode\u003epip\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install localstack\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can then list the available commands:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003elocalstack --help\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e If the command \u003ccode\u003elocalstack\u003c/code\u003e is not available after successfully installing the package, please ensure that the folder containing \u003ccode\u003epip\u003c/code\u003e binaries is configured in your \u003ccode\u003e$PATH\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id="environment-setup"\u003eEnvironment Setup\u003c/h2\u003e\n\u003cp\u003eUsing the Pro services requires a valid subscription with an API key. Your API keys are listed on the \u003ca href="https://app.localstack.cloud/account/subscriptions"\u003esubscriptions page\u003c/a\u003e, and can be activated using the environment variable \u003ccode\u003eLOCALSTACK_API_KEY\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExample:\u003c/strong\u003e In order to use the API key \u003ccode\u003ekey123\u003c/code\u003e, use the following command in your environment:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport LOCALSTACK_API_KEY=key123\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eIMPORTANT NOTE:\u003c/strong\u003e If you are posting any commands, logs, or screenshots from your LocalStack installation (e.g., when reporting an issue on Github or in the community Slack channel), please always make sure to hide or \u003cstrong\u003eremove the \u003ccode\u003eLOCALSTACK_API_KEY\u003c/code\u003e variable from the output\u003c/strong\u003e!\u003c/p\u003e\n\u003ch2 id="updating"\u003eUpdating\u003c/h2\u003e\n\u003cp\u003eMake sure to run the following commands to update to the latest version:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install --upgrade localstack localstack-ext localstack-client\ndocker pull localstack/localstack\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePlease also kill and remove any LocalStack Docker containers on your machine when updating to the latest version.\u003c/p\u003e\n\u003ch2 id="api-key-caching"\u003eAPI Key Caching\u003c/h2\u003e\n\u003cp\u003eLocalStack Pro provides a mechanism to cache the API key activation on your local machine, allowing you to work offline or to continue using LocalStack in case of any network issues. The cached tokens are stored by default under \u003ccode\u003e/tmp/localstack/.localstack\u003c/code\u003e inside the container, therefore please make sure to mount \u003ccode\u003e/tmp/localstack\u003c/code\u003e as a persistent folder from your local machine. For example, if you\u0026rsquo;re using docker-compose:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evolumes:\n  - \u0026quot;${TMPDIR:-/tmp/localstack}:/tmp/localstack\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith the configuration above, you\u0026rsquo;ll need connectivity for the first API key activation, and then the cached auth token can be used for up to 12h.\u003c/p\u003e\n'},{id:2,href:"/docs/getting-started/starting-up/",title:"Starting Up",description:"",content:'\u003cp\u003eTo start the LocalStack platform in your local Docker environment:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSERVICES=... localstack start\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe environment variable \u003ccode\u003eSERVICES\u003c/code\u003e is a comma-separated list of services (see available services \u003ca href="#available-services"\u003ehere\u003c/a\u003e). We recommend limiting the list of services to start up (e.g., \u003ccode\u003eSERVICES=lambda,s3,cognito,rds\u003c/code\u003e), to keep a low memory footprint and optimize performance.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePlease note:\u003c/strong\u003e Starting with version \u003ccode\u003e0.11.0\u003c/code\u003e, all services are exposed via a single edge service endpoint - \u003ccode\u003ehttp://localhost:4566\u003c/code\u003e by default. (The old service-specific port numbers from previous releases are now deprecated and disabled.)\u003c/p\u003e\n\u003ch2 id="running-in-docker-compose"\u003eRunning In Docker Compose\u003c/h2\u003e\n\u003cp\u003eAlternatively, you can also spin up LocalStack using \u003ca href="https://docs.docker.com/compose/"\u003eDocker Compose\u003c/a\u003e. Below is a sample \u003ccode\u003edocker-compose.yml\u003c/code\u003e configuration file that can be used as a starting point (please make sure to fill in \u003ccode\u003eLOCALSTACK_API_KEY\u003c/code\u003e, and that the port ranges correspond to the services you\u0026rsquo;re starting):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eversion: \'2.1\'\nservices:\n  localstack:\n    image: localstack/localstack\n    ports:\n      - \u0026quot;127.0.0.1:53:53\u0026quot;\n      - \u0026quot;127.0.0.1:443:443\u0026quot;\n      - \u0026quot;127.0.0.1:4510-4530:4510-4530\u0026quot;\n      - \u0026quot;127.0.0.1:4566-4620:4566-4620\u0026quot;\n    environment:\n      - LOCALSTACK_API_KEY=...\n      - SERVICES=serverless,cognito,rds\n      - DEBUG=1\n      - DATA_DIR=/tmp/localstack/data\n      - DOCKER_HOST=unix:///var/run/docker.sock\n      - HOST_TMP_FOLDER=${TMPDIR}\n    volumes:\n      - \u0026quot;${TMPDIR:-/tmp/localstack}:/tmp/localstack\u0026quot;\n      - \u0026quot;/var/run/docker.sock:/var/run/docker.sock\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e Please make sure to mount a persistent temporary folder \u003ccode\u003e/tmp/localstack\u003c/code\u003e into the container, as this is required to enable \u003cstrong\u003eAPI key caching\u003c/strong\u003e, allowing you to work offline (see \u003ca href="#api-key-caching"\u003ethis section\u003c/a\u003e for more details).\u003c/p\u003e\n'},{id:3,href:"/docs/getting-started/configuration/",title:"Configuration",description:"Configuration options for LocalStack",content:'\u003cp\u003eLocalStack provides a number of configuration options that can be set via environment variables.\nFollowing environment variables are available in LocalStack Pro.\u003c/p\u003e\n\u003ch3 id="dns_address"\u003eDNS_ADDRESS\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eDNS_ADDRESS\u003c/code\u003e configures the IP address that the local DNS server should be bound to (default: \u003ccode\u003e0.0.0.0\u003c/code\u003e).\nCan be configured to avoid port clashes in case a DNS server is already running on \u003ccode\u003elocalhost\u003c/code\u003e port \u003ccode\u003e53\u003c/code\u003e.\nSet to \u003ccode\u003e0\u003c/code\u003e or \u003ccode\u003efalse\u003c/code\u003e to avoid exposing DNS port altogether.\u003c/p\u003e\n\u003ch3 id="dns_resolve_ip"\u003eDNS_RESOLVE_IP\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eDNS_RESOLVE_IP\u003c/code\u003e configures the IP address that AWS hostnames should resolve to for transparent execution mode (default: \u003ccode\u003e127.0.0.1\u003c/code\u003e).\nIf your code is running in Docker, this should be configured to resolve to the Docker bridge network address, e.g., \u003ccode\u003eDNS_RESOLVE_IP=172.17.0.1\u003c/code\u003e.\u003c/p\u003e\n\u003ch3 id="dns_server"\u003eDNS_SERVER\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eDNS_SERVER\u003c/code\u003e configures the IP address of the fallback DNS server used to resolve non-AWS DNS names (default: \u003ccode\u003e8.8.8.8\u003c/code\u003e).\u003c/p\u003e\n\u003ch3 id="dns_local_name_patterns"\u003eDNS_LOCAL_NAME_PATTERNS\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eDNS_LOCAL_NAME_PATTERNS\u003c/code\u003e can be configures as a comma-separated list of regex patterns for DNS names to resolve locally (e.g., \u003ccode\u003e\'.*cloudfront\\.net\'\u003c/code\u003e).\nCan be used to whitelist certain host names to resolve to local endpoints, while resolving any non-matching AWS host names to their real DNS entries.\u003c/p\u003e\n\u003ch3 id="cloudfront_static_ports"\u003eCLOUDFRONT_STATIC_PORTS\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eCLOUDFRONT_STATIC_PORTS\u003c/code\u003e determines whether to use separate ports for each CloudFront distribution (e.g., \u003ccode\u003elocalhost:4511\u003c/code\u003e)\ninstead of locally resolvable hostnames (e.g., \u003ccode\u003eabc123.cloudfront.net\u003c/code\u003e).\nCan be useful in case you prefer not to use the local DNS server.\u003c/p\u003e\n\u003ch3 id="smtp_host--smtp_user--smtp_pass--smtp_email"\u003eSMTP_HOST / SMTP_USER / SMTP_PASS / SMTP_EMAIL\u003c/h3\u003e\n\u003cp\u003eThe environment variables \u003ccode\u003eSMTP_HOST\u003c/code\u003e/\u003ccode\u003eSMTP_USER\u003c/code\u003e/\u003ccode\u003eSMTP_PASS\u003c/code\u003e/\u003ccode\u003eSMTP_EMAIL\u003c/code\u003e can be used to setup the SMTP configuration\n(host, username, password, and sender address) to use when sending automated test emails in the platform\n(e.g., to send Cognito signup confirmation codes)\u003c/p\u003e\n\u003ch3 id="enforce_iam"\u003eENFORCE_IAM\u003c/h3\u003e\n\u003cp\u003eVariable \u003ccode\u003eENFORCE_IAM\u003c/code\u003e determines whether to enforce IAM security policies when processing client requests (default: \u003ccode\u003efalse\u003c/code\u003e)\u003c/p\u003e\n\u003ch3 id="autostart_util_containers"\u003eAUTOSTART_UTIL_CONTAINERS\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eAUTOSTART_UTIL_CONTAINERS\u003c/code\u003e determines whether to automatically start up utility containers (e.g., Spark/Hadoop for EMR, Presto for Athena)\u003c/p\u003e\n\u003ch3 id="disable_events"\u003eDISABLE_EVENTS\u003c/h3\u003e\n\u003cp\u003eSet the \u003ccode\u003eDISABLE_EVENTS\u003c/code\u003e flag to disable sending of anonymized usage events (default: \u003ccode\u003efalse\u003c/code\u003e).\n(Note that this will disable the Web dashboard and any analytics features.)\u003c/p\u003e\n\u003ch3 id="service_instances_ports_start-service_instances_ports_end"\u003eSERVICE_INSTANCES_PORTS_START-SERVICE_INSTANCES_PORTS_END\u003c/h3\u003e\n\u003cp\u003eVariables \u003ccode\u003eSERVICE_INSTANCES_PORTS_START\u003c/code\u003e-\u003ccode\u003eSERVICE_INSTANCES_PORTS_END\u003c/code\u003e determine the start and end ports for service instances\nbeing created, e.g., WebSocket APIs, RDS instances, etc (default: \u003ccode\u003e4510\u003c/code\u003e-\u003ccode\u003e4530\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eFor a complete list of configuration options, please refer to the \u003ca href="https://github.com/localstack/localstack"\u003eREADME in the public Github repo\u003c/a\u003e.\u003c/p\u003e\n'},{id:4,href:"/docs/how-to/overview/",title:"How-to Guides",description:"A collection of guides of how to integrate LocalStack with various tools.",content:"\u003cp\u003eThe best way to get started with LocalStack is to check out one of our How-to guides.\nThere you will find guidance of how to integrate LocalStack with your favorite Infrastructure-as-Code (IaC) tools\nsuch as CloudFormation, the Serverless Framework, etc. as well CI/CD platforms like CircleCI.\u003c/p\u003e\n"},{id:5,href:"/docs/how-to/serverless/",title:"How to integrate LocalStack with the Serverless Framework",description:"This guide explains how to integrate LocalStack with the Serverless Framework",content:'\u003cimg class="img-simple img-fluid lazyload blur-up" src="/docs/how-to/serverless/serverless_hu671c167b987b207635f597317b014e15_85393_20x0_resize_box_2.png" data-src="/docs/how-to/serverless/serverless.png" width="2637" height="789" alt="The Serverless Framework"\u003e\n\u003cp\u003eThis guide explains how to integrate LocalStack with the \u003ca href="https://www.serverless.com/"\u003eServerless Framework\u003c/a\u003e.\nAlthough it probably requires a few code changes, integrating LocalStack with the Serverless Framework is fairly straightforward.\u003c/p\u003e\n\u003cp\u003eIn particular, the setup consists of the following two steps.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eInstalling and configuring the \u003ca href="https://github.com/localstack/serverless-localstack"\u003eServerless-LocalStack plugin\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eAdjusting AWS endpoints in Lambda functions.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id="prerequisites"\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003eThis guide assumes that you have the following tools installed.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLocalStack (\u003ca href="https://localstack.cloud/docs/getting-started/installation/"\u003eInstall\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eServerless (\u003ca href="https://www.serverless.com/framework/docs/getting-started/"\u003eInstall\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIt also assumes that you already have a Serverless app set up consisting of a couple of Lambda functions and a \u003ccode\u003eserverless.yml\u003c/code\u003e file similar to the following. An example Serverless app integrated with LocalStack can be found \u003ca href="https://github.com/localstack/serverless-python-rest-api-with-dynamodb"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eservice: my-service\n\nframeworkVersion: \u0026quot;\u0026gt;=1.1.0 \u0026lt;=2.50.0\u0026quot;\n\nprovider:\n  name: aws\n  runtime: python3.8\n  environment:\n    DYNAMODB_TABLE: ${self:service}-${opt:stage, self:provider.stage}\n  iamRoleStatements:\n    - Effect: Allow\n      Action:\n        - dynamodb:Query\n        - ...\n      Resource: \u0026quot;arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE}\u0026quot;\n\nfunctions:\n  create:\n    handler: todos/create.create\n    events:\n      - http:\n          path: todos\n          method: post\n          cors: true\n\n  ...\n\nresources:\n  Resources:\n    TodosDynamoDbTable:\n      Type: \'AWS::DynamoDB::Table\'\n      DeletionPolicy: Retain\n      Properties:\n        ...\n        TableName: ${self:provider.environment.DYNAMODB_TABLE}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="install-and-configure-serverless-localstack-plugin"\u003eInstall and configure Serverless-LocalStack Plugin\u003c/h2\u003e\n\u003cp\u003eTo install the plugin, execute the following command in the root of your project.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003enpm install -D serverless-localstack\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNext, set up the plugin by adding the following properties to \u003ccode\u003eserverless.yml\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e...\n\nplugins:\n  - serverless-localstack\n\ncustom:\n  localstack:\n    stages:\n      - local\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis sets up Serverless to use the LocalStack plugin but only for the stage \u0026ldquo;local\u0026rdquo;.\nNext, you need make minor adjustments to your function code in order to make your application work no matter if it is deployed on AWS or LocalStack.\u003c/p\u003e\n\u003ch2 id="adjust-aws-endpoints-in-lambda-functions"\u003eAdjust AWS endpoints in Lambda functions\u003c/h2\u003e\n\u003cp\u003eYou are likely using an AWS SDK (such as \u003ca href="https://github.com/boto/boto3"\u003eBoto3\u003c/a\u003e for Python) in your Lambda functions to interact with other AWS services such as DynamoDB.\u003c/p\u003e\n\u003cp\u003eFor example, in Python, your code to set up a connection to DynamoDB may look like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-python"\u003e...\ndynamodb = boto3.resource(\'dynamodb\')\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBy default, this call attempts to create a connection via the usual AWS endpoints. However, when running services in LocalStack, we need to make sure, our applications creates a connection via the LocalStack endpoint instead.\u003c/p\u003e\n\u003cp\u003eUsually, all of LocalStack\u0026rsquo;s services are available via a specific port on localhost (e.g. \u003ccode\u003elocalhost:4566\u003c/code\u003e). However, this endpoint only works when accessing LocalStack from outside its Docker runtime.\u003c/p\u003e\n\u003cp\u003eSince the Lambda functions execute within the LocalStack Docker container, Lambda functions cannot access other services via the usual localhost endpoint.\u003c/p\u003e\n\u003cp\u003eInstead, LocalStack provides a special environment variable \u003ccode\u003eLOCALSTACK_HOSTNAME\u003c/code\u003e which contains the internal endpoint of the LocalStack services from within its runtime environment.\u003c/p\u003e\n\u003cp\u003eHence, you need to configure the Lambda functions to use the \u003ccode\u003eLOCALSTACK_HOSTNAME\u003c/code\u003e endpoint when accessing other AWS services in LocalStack.\u003c/p\u003e\n\u003cp\u003eIn Python, this may look something like. The code detects if it is running in LocalStack by checking if the \u003ccode\u003eLOCALSTACK_HOSTNAME\u003c/code\u003e variable exists and then configures the endpoint URL accordingly.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-python"\u003e...\nif \'LOCALSTACK_HOSTNAME\' in os.environ:\n    dynamodb_endpoint = \'http://%s:4566\' % os.environ[\'LOCALSTACK_HOSTNAME\']\n    dynamodb = boto3.resource(\'dynamodb\', endpoint_url=dynamodb_endpoint)\nelse:\n    dynamodb = boto3.resource(\'dynamodb\')\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIdeally, we want to make LocalStack\u0026rsquo;s Lambda execution environment \u0026ldquo;LocalStack-agnostic\u0026rdquo;, so that you are not required to adjust endpoints in your function code anymore. You want to help us with that? \u003ca href="https://localstack-community.slack.com"\u003eDrop us a line in Slack\u003c/a\u003e!.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id="deploying-to-localstack"\u003eDeploying to LocalStack\u003c/h2\u003e\n\u003cp\u003eYou can now deploy your Serverless service to LocalStack.\u003c/p\u003e\n\u003cp\u003eFirst, start LocalStack by running\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003elocalstack start\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen deploy the endpoint by running\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003eserverless deploy --stage local\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe expected result should be similar to:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003eServerless: Packaging service...\nServerless: Excluding development dependencies...\nServerless: Creating Stack...\nServerless: Checking Stack create progress...\n........\nServerless: Stack create finished...\nServerless: Uploading CloudFormation file to S3...\nServerless: Uploading artifacts...\nServerless: Uploading service my-service.zip file to S3 (38.3 KB)...\nServerless: Validating template...\nServerless: Skipping template validation: Unsupported in Localstack\nServerless: Updating Stack...\nServerless: Checking Stack update progress...\n.....................................\nServerless: Stack update finished...\nService Information\nservice: my-service\nstage: local\nregion: us-east-1\nstack: my-service-local\nresources: 35\napi keys:\n  None\nendpoints:\n  http://localhost:4566/restapis/XXXXXXXXXX/local/_user_request_\nfunctions:\n  ...\nlayers:\n  None\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUse the displayed endpoint \u003ccode\u003ehttp://localhost:4566/restapis/XXXXXXXXXX/local/_user_request_/my/custom/endpoint\u003c/code\u003e to make requests to the deployed service.\u003c/p\u003e\n\u003ch2 id="ran-into-trouble"\u003eRan into trouble?\u003c/h2\u003e\n\u003cp\u003eIf you run into any issues or problems while integrating LocalStack with your Serverless app, please \u003ca href="https://github.com/localstack/serverless-localstack/issues"\u003esubmit an issue\u003c/a\u003e.\u003c/p\u003e\n'},{id:6,href:"/docs/reference/amplify/",title:"Amplify",description:"",content:"\u003cp\u003eDetails coming soon.\u003c/p\u003e\n"},{id:7,href:"/docs/reference/apigatewayv2/",title:"API Gateway V2",description:"",content:'\u003cp\u003eBasic support for API Gateway V2 is included in the Pro version, which allows for creation of local WebSocket APIs for long-lived connections and bi-directional communication between the API and your clients.\u003c/p\u003e\n\u003cp\u003eFor example, given the following \u003ca href="https://serverless.com/"\u003eServerless\u003c/a\u003e configuration:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e...\nplugins:\n  - serverless-localstack\nfunctions:\n  actionHandler:\n    handler: handler.handler\n    events:\n      - websocket:\n          route: test-action\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUpon deployment of the Serverless project, a new API Gateway V2 endpoint will be created in LocalStack. The \u003ca href="https://github.com/localstack/awscli-local"\u003e\u003ccode\u003eawslocal\u003c/code\u003e\u003c/a\u003e CLI can be used to get the list of APIs, which should contain the WebSocket endpoint, e.g., \u003ccode\u003ews://localhost:4510\u003c/code\u003e in the example below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal apigatewayv2 get-apis\n{\n    \u0026quot;Items\u0026quot;: [{\n        \u0026quot;ApiEndpoint\u0026quot;: \u0026quot;ws://localhost:4510\u0026quot;,\n        \u0026quot;ApiId\u0026quot;: \u0026quot;129ca37e\u0026quot;,\n        ...\n    }]\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAssuming your project contains a simple Lambda \u003ccode\u003ehandler.js\u003c/code\u003e like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emodule.exports.handler = function(event, context, callback) {\n  callback(null, event);\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u0026hellip; then sending a message to the WebSocket at \u003ccode\u003ews://localhost:4510\u003c/code\u003e will result in the same message getting returned as a response on the same WebSocket.\u003c/p\u003e\n\u003cp\u003eFor a simple, self-contained example please refer to \u003ca href="https://github.com/localstack/localstack-pro-samples/tree/master/serverless-websockets"\u003ethis Github repository\u003c/a\u003e.\u003c/p\u003e\n'},{id:8,href:"/docs/reference/appsync/",title:"AppSync",description:"",content:'\u003cp\u003eBasic support for AppSync is included in LocalStack Pro. The local AppSync API allows you to spin up local GraphQL APIs and directly expose your data sources (e.g., DynamoDB tables) to external clients.\u003c/p\u003e\n\u003cp\u003eFor example, you can create a DynamoDB table \u003ccode\u003e\u0026quot;posts\u0026quot;\u003c/code\u003e with a key attribute \u003ccode\u003eid\u003c/code\u003e, and define a GraphQL schema in a file \u003ccode\u003eschema.graphql\u003c/code\u003e like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eschema {\n    query: Query\n}\ntype Query {\n    getPosts: [Post!]!\n}\ntype Post {\n    id: DDBString!\n}\ntype DDBString {\n    S: String!\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u0026hellip; and then use the AppSync API (or CloudFormation) to create the following entities:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ea GraphQL API\u003c/li\u003e\n\u003cli\u003ea data source of type \u003ccode\u003eAMAZON_DYNAMODB\u003c/code\u003e that references the \u003ccode\u003e\u0026quot;posts\u0026quot;\u003c/code\u003e DynamoDB table\u003c/li\u003e\n\u003cli\u003ea request mapping template with a content like this:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \u0026quot;version\u0026quot; : \u0026quot;2017-02-28\u0026quot;,\n    \u0026quot;operation\u0026quot; : \u0026quot;Scan\u0026quot;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start="4"\u003e\n\u003cli\u003ea response mapping template with a content like this:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$util.toJson($context.result[\u0026quot;Items\u0026quot;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce things have been wired up properly, and assuming the ID of your GraphQL API is \u003ccode\u003e\u0026quot;api123\u0026quot;\u003c/code\u003e, you should be able to run the following GraphQL query to retrieve all items from the \u003ccode\u003e\u0026quot;posts\u0026quot;\u003c/code\u003e DynamoDB table:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecurl -d \'{\u0026quot;query\u0026quot;:\u0026quot;query {getPosts{id{S}}}\u0026quot;}\' http://localhost:4605/graphql/api123\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor more details, please refer to the self-contained sample published in \u003ca href="https://github.com/localstack/localstack-pro-samples/tree/master/appsync-graphql-api"\u003ethis Github repository\u003c/a\u003e.\u003c/p\u003e\n'},{id:9,href:"/docs/reference/athena/",title:"Athena",description:"",content:'\u003cp\u003eLocalStack Pro ships with built-in support for \u003ca href="https://aws.amazon.com/athena"\u003eAthena\u003c/a\u003e, Amazon\u0026rsquo;s serverless data warehouse and analytics platform. Athena uses \u003ca href="https://prestodb.github.io/"\u003ePresto\u003c/a\u003e under the covers, and your Athena instance will be automatically configured with a Hive metastore that connects seamlessly to the LocalStack S3 API. That is, you can easily connect your local S3 buckets and query data directly from S3 via the powerful Athena query API.\u003c/p\u003e\n\u003cp\u003eThe following commands illustrate how to use Athena from the command line (assuming you have \u003ca href="https://github.com/localstack/awscli-local"\u003e\u003ccode\u003eawslocal\u003c/code\u003e\u003c/a\u003e installed):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal athena start-query-execution --query-string \'SELECT 1, 2, 3\'\n{\n    \u0026quot;QueryExecutionId\u0026quot;: \u0026quot;c9f453ad\u0026quot;\n}\n$ awslocal athena list-query-executions\n{\n    \u0026quot;QueryExecutionIds\u0026quot;: [\n        \u0026quot;c9f453ad\u0026quot;\n    ]\n}\n$ awslocal athena get-query-results --query-execution-id c9f453ad\n{\n    \u0026quot;ResultSet\u0026quot;: {\n        \u0026quot;Rows\u0026quot;: [{\n            \u0026quot;Data\u0026quot;: [\n                { \u0026quot;VarCharValue\u0026quot;: \u0026quot;1\u0026quot; },\n                { \u0026quot;VarCharValue\u0026quot;: \u0026quot;2\u0026quot; },\n                { \u0026quot;VarCharValue\u0026quot;: \u0026quot;3\u0026quot; }\n            ]\n        }],\n        \u0026quot;ResultSetMetadata\u0026quot;: { \u0026quot;ColumnInfo\u0026quot;: [] }\n    },\n    \u0026quot;UpdateCount\u0026quot;: 0\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e In order to use the Athena API, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.2GB which includes Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you\u0026rsquo;re on a decent internet connection when pulling the dependencies for the first time.\u003c/p\u003e\n'},{id:10,href:"/docs/reference/backup/",title:"Backup",description:"",content:'\u003cp\u003eThe \u003ca href="https://docs.aws.amazon.com/aws-backup/"\u003eBackup API\u003c/a\u003e allows to manage backup plans, to create scheduled or on-demand backups of certain resource types like DynamoDB tables or RDS databases. Details following soon\u0026hellip;\u003c/p\u003e\n'},{id:11,href:"/docs/reference/cloudfront/",title:"CloudFront",description:"",content:"\u003cp\u003eLocalStack Pro supports creation of local CloudFront distributions, which allows you to transparently access your applications and file artifacts via CloudFront URLs like \u003ccode\u003ehttps://abc123.cloudfront.net\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor example, take the following simple example which creates an S3 bucket, puts a small text file \u003ccode\u003ehello.txt\u003c/code\u003e to the bucket, and then creates a CloudFront distribution which makes the file accessible via a \u003ccode\u003ehttps://abc123.cloudfront.net/hello.txt\u003c/code\u003e proxy URL (where \u003ccode\u003eabc123\u003c/code\u003e is a placeholder for the real distribution ID):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal s3 mb s3://bucket1\n$ echo 'Hello World' \u0026gt; /tmp/hello.txt\n$ awslocal s3 cp /tmp/hello.txt s3://bucket1/hello.txt --acl public-read\n$ domain=$(awslocal cloudfront create-distribution \\\n  --origin-domain-name bucket1.s3.amazonaws.com | jq -r '.Distribution.DomainName')\n$ curl -k https://$domain/hello.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e In order for CloudFront to be fully functional, your local DNS setup needs to be properly configured. See the section on \u003ca href=\"#configuring-local-dns-server\"\u003econfiguring the local DNS server\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e In the code example above, the last command (\u003ccode\u003ecurl https://$domain/hello.txt\u003c/code\u003e) may temporarily fail with a warning message \u003ccode\u003eCould not resolve host\u003c/code\u003e. This is due to the fact that operating systems use different DNS caching strategies, and it may take some time for the CloudFront distribution\u0026rsquo;s DNS name (e.g., \u003ccode\u003eabc123.cloudfront.net\u003c/code\u003e) to become available in the system. Usually after a few retries the command should work, though. Note that a similar behavior can also be observed in the real AWS - CloudFront DNS names can also take up to 10-15 minutes to propagate across the network.\u003c/p\u003e\n"},{id:12,href:"/docs/reference/codecommit/",title:"CodeCommit",description:"",content:'\u003cp\u003eLocalStack Pro contains basic support for CodeCommit code repositories. The CodeCommit API can be used to create Git repositories, clone these repos to local folders, push commits with changes, etc.\u003c/p\u003e\n\u003cp\u003eA simple example has been added in \u003ca href="https://github.com/localstack/localstack-pro-samples/tree/master/codecommit-git-repo"\u003ethis Github repository\u003c/a\u003e. The sample creates an Git repository via the AWS CodeCommit API locally, commits and pushes a test file to the repository, and then checks out the file in a fresh clone of the repository.\u003c/p\u003e\n\u003cp\u003ePlease note that CodeCommit is a fairly large API and currently not all methods are supported yet, but we are actively extending the implementation on an ongoing basis.\u003c/p\u003e\n'},{id:13,href:"/docs/reference/cognito/",title:"Cognito",description:"",content:'\u003cp\u003eLocalStack Pro contains basic support for authentication via \u003ca href="https://eu-central-1.console.aws.amazon.com/cognito/"\u003eAWS Cognito\u003c/a\u003e. You can create Cognito user pools, sign up and confirm users, and use the \u003ccode\u003eCOGNITO_USER_POOLS\u003c/code\u003e authorizer integration with API Gateway.\u003c/p\u003e\n\u003cp\u003eFor example, if you happen to use \u003ca href="https://serverless.com/"\u003eServerless\u003c/a\u003e to deploy your application, take this snippet of a \u003ccode\u003eserverless.yml\u003c/code\u003e configuration:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eservice: test\n\nplugins:\n  - serverless-deployment-bucket\n  - serverless-pseudo-parameters\n  - serverless-localstack\n\ncustom:\n  localstack:\n    stages: [local]\n\nfunctions:\n  http_request:\n    handler: http.request\n    events:\n      - http:\n          path: v1/request\n          authorizer:\n            arn: arn:aws:cognito-idp:us-east-1:#{AWS::AccountId}:userpool/UserPool\n\nresources:\n  Resources:\n    UserPool:\n      Type: AWS::Cognito::UserPool\n      Properties:\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis configuration can be directly deployed using \u003ccode\u003eserverless deploy --stage local\u003c/code\u003e. The example contains a Lambda function \u003ccode\u003ehttp_request\u003c/code\u003e which is connected to an API Gateway endpoint. Once deployed, the \u003ccode\u003ev1/request\u003c/code\u003e API Gateway endpoint will be secured against the Cognito user pool \u003ccode\u003e\u0026quot;UserPool\u0026quot;\u003c/code\u003e. You can then register users against that local pool, using the same API calls as for AWS. In order to make request against the secured API Gateway endpoint, use the local Cognito API to retrieve identity credentials which can be sent along as \u003ccode\u003eAuthentication\u003c/code\u003e HTTP headers (where \u003ccode\u003etest-1234567\u003c/code\u003e is the name of the access key ID generated by Cognito):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eAuthentication: AWS4-HMAC-SHA256 Credential=test-1234567/20190821/us-east-1/cognito-idp/aws4_request ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="oauth-flows-via-cognito-login-form"\u003eOAuth Flows via Cognito Login Form\u003c/h3\u003e\n\u003cp\u003eIn order to access the local \u003ca href="https://docs.aws.amazon.com/cognito/latest/developerguide/login-endpoint.html"\u003eCognito login form\u003c/a\u003e, try accessing the following URL in your browser. Please replace \u003ccode\u003e\u0026lt;client_id\u0026gt;\u003c/code\u003e with the ID of an existing user pool ID, and \u003ccode\u003e\u0026lt;redirect_uri\u0026gt;\u003c/code\u003e with the redirect URL of your application (e.g., \u003ccode\u003ehttp://example.com\u003c/code\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehttp://localhost:4590/login?response_type=code\u0026amp;client_id=\u0026lt;client_id\u0026gt;\u0026amp;redirect_uri=\u0026lt;redirect_uri\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe login form should look similar to the screenshot below:\u003c/p\u003e\n\u003cimg class="img-simple img-fluid lazyload blur-up" src="/docs/reference/cognito/cognitoLogin_hu264b08270c3be9a8d599b17e51696108_53687_20x0_resize_box_2.png" data-src="/docs/reference/cognito/cognitoLogin.png" width="750" height="518" alt="Cognito Login"\u003e\n\u003cp\u003eAfter successful login, the page will redirect to the specified redirect URI, with a path parameter \u003ccode\u003e?code=\u0026lt;code\u0026gt;\u003c/code\u003e appended, e.g., \u003ccode\u003ehttp://example.com?code=test123\u003c/code\u003e. This authentication code can then be used to obtain a token via the Cognito OAuth2 TOKEN endpoint documented \u003ca href="https://docs.aws.amazon.com/cognito/latest/developerguide/token-endpoint.html"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n'},{id:14,href:"/docs/reference/elastic-container-registry/",title:"Elastic Container Registry (ECR)",description:"",content:"\u003cp\u003eA basic version of Elastic Container Registry (ECR) is available to store application images. ECR is often used in combination with other APIs that deploy containerized apps, like ECS or EKS.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal ecr create-repository --repository-name repo1\n{\n    \u0026quot;repository\u0026quot;: {\n        \u0026quot;repositoryArn\u0026quot;: \u0026quot;arn:aws:ecr:us-east-1:000000000000:repository/repo1\u0026quot;,\n        \u0026quot;registryId\u0026quot;: \u0026quot;abc898c8\u0026quot;,\n        \u0026quot;repositoryName\u0026quot;: \u0026quot;repo1\u0026quot;,\n        \u0026quot;repositoryUri\u0026quot;: \u0026quot;localhost:4510/repo1\u0026quot;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can then build and tag a new Docker image, and push it to the repository URL (\u003ccode\u003elocalhost:4510/repo1\u003c/code\u003e in the example above):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ cat Dockerfile\nFROM nginx\nENV foo=bar\n$ docker build -t localhost:4510/repo1 .\n...\nSuccessfully built e2cfb3cf012d\nSuccessfully tagged localhost:4510/repo1:latest\n$ docker push localhost:4510/repo1\nThe push refers to repository [localhost:4510/repo1]\n318be7aea8fc: Pushed\nfe08d5d042ab: Pushed\nf2cb0ecef392: Pushed\nlatest: digest: sha256:4dd893a43df24c8f779a5ab343b7ef172fb147c69ed5e1278d95b97fe0f584a5 size: 948\n...\n\u003c/code\u003e\u003c/pre\u003e\n"},{id:15,href:"/docs/reference/elastic-container-service/",title:"Elastic Container Service (ECS)",description:"",content:'\u003cp\u003eBasic support for creating and deploying containerized apps using \u003ca href="https://aws.amazon.com/ecs"\u003eECS\u003c/a\u003e is provided in the Pro version. LocalStack offers the basic APIs locally, including creation of ECS task definitions, services, and tasks.\u003c/p\u003e\n\u003cp\u003eBy default, the ECS Fargate launch type is assumed, i.e., the local Docker engine is used for deployment of applications, and there is no need to create and manage EC2 virtual machines to run the containers.\u003c/p\u003e\n\u003cp\u003eNote that more complex features like integration of application load balancers (ALBs) are currently not available, but are being developed and will be available in the near future.\u003c/p\u003e\n\u003cp\u003eTask instances are started in a local Docker engine which needs to be accessible to the LocalStack container. The name pattern for task containers is \u003ccode\u003elocalstack_\u0026lt;family\u0026gt;_\u0026lt;revision\u0026gt;\u003c/code\u003e, where \u003ccode\u003e\u0026lt;family\u0026gt;\u003c/code\u003e refers to the task family and \u003ccode\u003e\u0026lt;revision\u0026gt;\u003c/code\u003e refers to a task revision (for example, \u003ccode\u003elocalstack_nginx_1\u003c/code\u003e).\u003c/p\u003e\n'},{id:16,href:"/docs/reference/elastic-kubernetes-service/",title:"Elastic Kubernetes Service (EKS)",description:"",content:'\u003cp\u003eLocalStack Pro allows you to use the \u003ca href="https://docs.aws.amazon.com/eks/"\u003eEKS\u003c/a\u003e API to create Kubernetes clusters and easily deploy containerized apps locally.\u003c/p\u003e\n\u003cp\u003ePlease note that EKS requires an existing local Kubernetes installation. In recent versions of Docker, you can simply enable Kubernetes as an embedded service running inside Docker. See below for a screenshot of the Docker settings for Kubernetes in MacOS (similar configurations apply for Linux/Windows). By default, it is asssumed that Kubernetes API runs on the local TCP port \u003ccode\u003e6443\u003c/code\u003e.\u003c/p\u003e\n\u003cimg class="img-simple img-fluid lazyload blur-up" src="/docs/reference/elastic-kubernetes-service/kubernetes_huc1c177c26a58b85de35cd1361a38065b_172423_20x0_resize_box_2.png" data-src="/docs/reference/elastic-kubernetes-service/kubernetes.png" width="998" height="784" alt="Kubernetes in Docker"\u003e\n\u003cp\u003eThe example below illustrates how to create an EKS cluster configuration (assuming you have \u003ca href="https://github.com/localstack/awscli-local"\u003e\u003ccode\u003eawslocal\u003c/code\u003e\u003c/a\u003e installed):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal eks create-cluster --name cluster1 --role-arn r1 --resources-vpc-config \'{}\'\n{\n    \u0026quot;cluster\u0026quot;: {\n        \u0026quot;name\u0026quot;: \u0026quot;cluster1\u0026quot;,\n        \u0026quot;arn\u0026quot;: \u0026quot;arn:aws:eks:eu-central-1:000000000000:cluster/cluster1\u0026quot;,\n        \u0026quot;createdAt\u0026quot;: \u0026quot;Sat, 05 Oct 2019 12:29:26 GMT\u0026quot;,\n        \u0026quot;endpoint\u0026quot;: \u0026quot;https://172.17.0.1:6443\u0026quot;,\n        \u0026quot;status\u0026quot;: \u0026quot;ACTIVE\u0026quot;,\n        ...\n    }\n}\n$ awslocal eks list-clusters\n{\n    \u0026quot;clusters\u0026quot;: [\n        \u0026quot;cluster1\u0026quot;\n    ]\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSimply configure your Kubernetes client (e.g., \u003ccode\u003ekubectl\u003c/code\u003e or other SDK) to point to the \u003ccode\u003eendpoint\u003c/code\u003e specified in the \u003ccode\u003ecreate-cluster\u003c/code\u003e output above. Depending on whether you\u0026rsquo;re calling the Kubernetes API from the local machine or from within a Lambda, you may have to use different endpoint URLs (\u003ccode\u003ehttps://localhost:6443\u003c/code\u003e vs \u003ccode\u003ehttps://172.17.0.1:6443\u003c/code\u003e).\u003c/p\u003e\n'},{id:17,href:"/docs/reference/elastic-mapreduce/",title:"Elastic MapReduce (EMR)",description:"",content:'\u003cp\u003eLocalStack Pro allows running data analytics workloads locally via the \u003ca href="https://aws.amazon.com/emr"\u003eEMR\u003c/a\u003e API. EMR utilizes various tools in the \u003ca href="https://hadoop.apache.org/"\u003eHadoop\u003c/a\u003e and \u003ca href="https://spark.apache.org"\u003eSpark\u003c/a\u003e ecosystem, and your EMR instance is automatically configured to connect seamlessly to the LocalStack S3 API.\u003c/p\u003e\n\u003cp\u003eTo create a virtual EMR cluster locally from the command line (assuming you have \u003ca href="https://github.com/localstack/awscli-local"\u003e\u003ccode\u003eawslocal\u003c/code\u003e\u003c/a\u003e installed):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal emr create-cluster --release-label emr-5.9.0 --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=1,InstanceType=m4.large\n{\n    \u0026quot;ClusterId\u0026quot;: \u0026quot;j-A2KF3EKLAOWRI\u0026quot;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe commmand above will spin up one more more Docker containers on your local machine that can be used to run analytics workloads using Spark, Hadoop, Pig, and other tools.\u003c/p\u003e\n\u003cp\u003eNote that you can also specify startup commands using the \u003ccode\u003e--steps=...\u003c/code\u003e command line argument to the \u003ccode\u003ecreate-cluster\u003c/code\u003e command. A simple demo project with more details can be found in \u003ca href="https://github.com/localstack/localstack-pro-samples/tree/master/emr-hadoop-spark-jobs"\u003ethis Github repository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e In order to use the EMR API, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Spark, Hadoop, Pig and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you\u0026rsquo;re on a decent internet connection when pulling the dependencies for the first time.\u003c/p\u003e\n'},{id:18,href:"/docs/reference/elasticache/",title:"ElastiCache",description:"",content:'\u003cp\u003eA basic version of \u003ca href="https://aws.amazon.com/elasticache/"\u003eElastiCache\u003c/a\u003e is provided. By default, the API is started on http://localhost:4598 and supports running a local Redis instance (Memcached support coming soon).\u003c/p\u003e\n\u003cp\u003eAfter starting LocalStack Pro, you can test the following commands:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal elasticache create-cache-cluster --cache-cluster-id i1\n{\n    \u0026quot;CacheCluster\u0026quot;: {\n        \u0026quot;CacheClusterId\u0026quot;: \u0026quot;i1\u0026quot;,\n        \u0026quot;ConfigurationEndpoint\u0026quot;: {\n            \u0026quot;Address\u0026quot;: \u0026quot;localhost\u0026quot;,\n            \u0026quot;Port\u0026quot;: 4530\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen use the returned port number (\u003ccode\u003e4530\u003c/code\u003e) to connect to the Redis instance:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ redis-cli -p 4530 ping\nPONG\n$ redis-cli -p 4530 set foo bar\nOK\n$ redis-cli -p 4530 get foo\n\u0026quot;bar\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:19,href:"/docs/reference/glue/",title:"Glue",description:"",content:"\u003cp\u003eDetails and examples illustrating the Glue API coming soon\u0026hellip;\u003c/p\u003e\n"},{id:20,href:"/docs/reference/iam/",title:"Identity and Access Management (IAM)",description:"",content:"\u003cp\u003eBy default, LocalStack uses not enforce security policies for client requests. The IAM security enforcement feature can be used to test your security policies and create a more realistic environment that more closely resembles real AWS.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePlease note:\u003c/strong\u003e The environment configuration \u003ccode\u003eENFORCE_IAM=1\u003c/code\u003e is required to enable this feature (by default, IAM enforcement is disabled).\u003c/p\u003e\n\u003cp\u003eBelow is a simple example that illustrates the use of IAM policy enforcement. It first attempts to create an S3 bucket with the default user (which fails), then create a user and attempts to create a bucket with that user (which fails again), and then finally attaches a policy to the user to allow \u003ccode\u003es3:CreateBucket\u003c/code\u003e, which allows the bucket to be created.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal s3 mb s3://test\nmake_bucket failed: s3://test An error occurred (AccessDeniedException) when calling the CreateBucket operation: Access to the specified resource is denied\n$ awslocal iam create-user --user-name test\n...\n$ awslocal iam create-access-key --user-name test\n...\n  \u0026quot;AccessKeyId\u0026quot;: \u0026quot;AKIA4HPFP0TZHP3Z5VI6\u0026quot;,\n  \u0026quot;SecretAccessKey\u0026quot;: \u0026quot;mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua\u0026quot;,\n...\n$ export AWS_ACCESS_KEY_ID=AKIA4HPFP0TZHP3Z5VI6 AWS_SECRET_ACCESS_KEY=mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua\n$ awslocal s3 mb s3://test\nmake_bucket failed: s3://test An error occurred (AccessDeniedException) when calling the CreateBucket operation: Access to the specified resource is denied\n$ awslocal iam create-policy --policy-name p1 --policy-document '{\u0026quot;Version\u0026quot;:\u0026quot;2012-10-17\u0026quot;,\u0026quot;Statement\u0026quot;:[{\u0026quot;Effect\u0026quot;:\u0026quot;Allow\u0026quot;,\u0026quot;Action\u0026quot;:\u0026quot;s3:CreateBucket\u0026quot;,\u0026quot;Resource\u0026quot;:\u0026quot;*\u0026quot;}]}'\n...\n$ awslocal iam attach-user-policy --user-name test --policy-arn arn:aws:iam::000000000000:policy/p1\n$ awslocal s3 mb s3://test\nmake_bucket: test\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"supported-apis\"\u003eSupported APIs\u003c/h3\u003e\n\u003cp\u003eIAM security enforcement is available for the majority of LocalStack APIs - it has been tested, among others, for the following services: ACM, API Gateway, CloudFormation, CloudWatch (metrics/events/logs), DynamoDB, DynamoDB Streams, Elasticsearch Service, EventBus, Kinesis, KMS, Lambda, Redshift, S3 (partial support), SecretsManager, SNS, SQS.\u003c/p\u003e\n"},{id:21,href:"/docs/reference/iot/",title:"IoT",description:"",content:'\u003cp\u003eBasic support for \u003ca href="https://aws.amazon.com/iot/"\u003eIoT\u003c/a\u003e (including IoT Analytics, IoT Data, and related APIs) is provided in the Pro version. The main endpoints for creating and updating entities are currently implemented, as well as the CloudFormation integrations for creating them.\u003c/p\u003e\n\u003cp\u003eThe IoT API ships with a built-in MQTT message broker. In order to get the MQTT endpoint, the \u003ccode\u003edescribe-endpoint\u003c/code\u003e API can be used; for example, using \u003ca href="https://github.com/localstack/awscli-local"\u003e\u003ccode\u003eawslocal\u003c/code\u003e\u003c/a\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal iot describe-endpoint\n{\n    \u0026quot;endpointAddress\u0026quot;: \u0026quot;localhost:4520\u0026quot;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis endpoint can then be used with any MQTT client to send/receive messages (e.g., using the endpoint URL \u003ccode\u003emqtt://localhost:4520\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eLocalStack Pro also supports advanced features like SQL queries for IoT topic rules. For example, you can use the \u003ca href="https://docs.aws.amazon.com/iot/latest/apireference/API_CreateTopicRule.html"\u003e\u003ccode\u003eCreateTopicRule\u003c/code\u003e API\u003c/a\u003e to define a topic rule with a SQL query \u003ccode\u003eSELECT * FROM \'my/topic\' where attr=123\u003c/code\u003e which will trigger a Lambda function whenever a message with attribute \u003ccode\u003eattr=123\u003c/code\u003e is received on the MQTT topic \u003ccode\u003emy/topic\u003c/code\u003e.\u003c/p\u003e\n'},{id:22,href:"/docs/reference/kinesis/",title:"Kinesis Data Analytics",description:"",content:'\u003cp\u003eThe Kinesis Data Analytics API allows you to run continuous SQL queries directly over your Kinesis data streams. Basic support is included in LocalStack Pro - it allows you to create Kinesis Analytics applications, define input and output streams and schema types, and run continuous queries locally.\u003c/p\u003e\n\u003cp\u003eA simple example has been added to \u003ca href="https://github.com/localstack/localstack-pro-samples/tree/master/kinesis-analytics"\u003ethis sample repository on Github\u003c/a\u003e. More details are following soon.\u003c/p\u003e\n'},{id:23,href:"/docs/reference/lambda-layers/",title:"Lambda Layers",description:"",content:'\u003cp\u003e\u003ca href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html"\u003eLambda layers\u003c/a\u003e are a new AWS feature that allows to pull in additional code and content into your Lambda functions.\u003c/p\u003e\n\u003cp\u003eSimply point your Lambda client code at your LocalStack instance, e.g., running on http://localhost. For more details on how to use Lambda layers, please follow the documentation and examples on the \u003ca href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html"\u003eAWS website\u003c/a\u003e.\u003c/p\u003e\n'},{id:24,href:"/docs/reference/local-cloud-pods/",title:"Local Cloud Pods",description:"",content:'\u003cp\u003eLocal Cloud Pods are a mechanism that allows you to take a snapshot of your local instance, persist it to a storage backend (e.g., git repository), and easily share it out with your team members.\u003c/p\u003e\n\u003cp\u003eYou can create and manage local Cloud pods via the Web UI, and in order to load and store the persistent state of pods you can use the \u003ccode\u003elocalstack\u003c/code\u003e command line interface (CLI).\u003c/p\u003e\n\u003cp\u003eBelow is a simple example of how you can push and pull Local Cloud Pods using the \u003ccode\u003elocalstack\u003c/code\u003e command line:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# User 1 pushes state of Cloud Pod to persistent server\n$ awslocal kinesis list-streams\n{\u0026quot;StreamNames\u0026quot;: [\u0026quot;mystream123\u0026quot;]}\n$ localstack pod push mypod1\n...\n\n# User 2 pulls state from the server to local instance\n$ localstack pod pull mypod1\n$ awslocal kinesis list-streams\n{\u0026quot;StreamNames\u0026quot;: [\u0026quot;mystream123\u0026quot;]}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: Using local Cloud pods requires setting the \u003ccode\u003eDATA_DIR\u003c/code\u003e configuration variable to point to a folder on your local machine - this folder will be used to persist and load the state of cloud pods in your local instance.\u003c/p\u003e\n\u003cp\u003eLocal Cloud Pods support different storage mechanisms - currently we\u0026rsquo;re focusing on using \u003ccode\u003egit\u003c/code\u003e repositories as the storage backend, as \u003ccode\u003egit\u003c/code\u003e is often readily available on developers\' machines and is easy to integrate with (no additional access control settings required). Support for more storage backends is following soon (e.g., S3 buckets, FTP servers, etc).\u003c/p\u003e\n\u003cp\u003eYou can use the LocalStack Web UI to create a new local cloud pod - see screenshot below (make sure to adjust Git URL and branch name to point to your repo).\u003c/p\u003e\n\u003cimg class="img-simple img-fluid lazyload blur-up" src="/docs/reference/local-cloud-pods/cloudPodsUI_hu85f971449fd922a6946a49cfc541c84b_46086_20x0_resize_box_2.png" data-src="/docs/reference/local-cloud-pods/cloudPodsUI.png" width="1620" height="374" alt="Local Cloud Pods UI"\u003e\n\u003cp\u003eOnce the pod has been created, you should be able to login and list it via the CLI as well:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ export LOCALSTACK_API_KEY=...\n$ localstack login\n...\n$ localstack pod list\nName    Backend    URL                                Size    State\n------  ---------  ---------------------------------  ------  -------\npod1    git        ssh://git@github.com/your_org/...  1.68MB  Shared\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(\u003cstrong\u003eNote\u003c/strong\u003e: Please ensure that \u003ccode\u003eLOCALSTACK_API_KEY\u003c/code\u003e is properly configured in the terminal session above.)\u003c/p\u003e\n\u003cp\u003eAfter the pod definition has been created, you should be able to use the \u003ccode\u003epush\u003c/code\u003e/\u003ccode\u003epull\u003c/code\u003e commands listed above to push and pull the pod state to the Git repo. After \u003ccode\u003epull\u003c/code\u003eing the pod, LocalStack will automatically restart and restore the pod state in your instance (this may take a few moments to complete).\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: If you \u003ccode\u003epull\u003c/code\u003e a local cloud pod, it will overwrite the entire state in your LocalStack instance. Please make sure to backup any data before pulling a cloud pod, if required.\u003c/p\u003e\n'},{id:25,href:"/docs/reference/local-dns-server/",title:"Local DNS Server",description:"",content:'\u003cp\u003eLocalStack Pro supports transparent execution mode, which means that your application code automatically accesses the LocalStack APIs on \u003ccode\u003elocalhost\u003c/code\u003e, as opposed to the real APIs on AWS. In contrast, the community (open source) edition requires the application code to configure each AWS SDK client instance with the target \u003ccode\u003eendpoint URL\u003c/code\u003e to point to the respective ports on \u003ccode\u003elocalhost\u003c/code\u003e (see list of default ports \u003ca href="https://github.com/localstack/localstack"\u003ehere\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eWhen the system starts up, the log output contains the IP address of the local DNS server. Typically, this address by default is either \u003ccode\u003e0.0.0.0\u003c/code\u003e (see example below) or \u003ccode\u003e200.200.55.55\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eStarting DNS servers (tcp/udp port 53 on 0.0.0.0)...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn order to use transparent execution mode, the system needs to be configured to use the predefined DNS server. The DNS configuration depends on the operating system: in Mac OS it can be configured in the Network System Settings, under Linux this is usually achieved by configuring \u003ccode\u003e/etc/resolv.conf\u003c/code\u003e as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003enameserver 0.0.0.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe example above needs to be adjusted to the actual IP address of the DNS server. You can also configure a custom IP address by setting the \u003ccode\u003eDNS_ADDRESS\u003c/code\u003e environment variable (e.g., \u003ccode\u003eDNS_ADDRESS=200.200.55.55\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e Please be careful when changing the network configuration on your system, as this may have undesired side effects.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: When you configure transparent execution mode, you may still have to configure your application\u0026rsquo;s AWS SDK to \u003cstrong\u003eaccept self-signed certificates\u003c/strong\u003e. This is a technical limitation caused by the SSL certificate validation mechanism, due to the fact that we are repointing AWS domain names (e.g., \u003ccode\u003e*.amazonaws.com\u003c/code\u003e) to \u003ccode\u003elocalhost\u003c/code\u003e. For example, the following command will fail with an SSL error:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ aws kinesis list-streams\nSSL validation failed for https://kinesis.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1076)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u0026hellip; whereas the following command works:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ PYTHONWARNINGS=ignore aws --no-verify-ssl kinesis list-streams\n{\n    \u0026quot;StreamNames\u0026quot;: []\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDisabling SSL validation depends on the programming language and version of the AWS SDK used. For example, the \u003ca href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#boto3.session.Session.client"\u003e\u003ccode\u003eboto3\u003c/code\u003e AWS SDK for Python\u003c/a\u003e provides a parameter \u003ccode\u003everify=False\u003c/code\u003e to disable SSL verification. Similar parameters are available for most other AWS SDKs.\u003c/p\u003e\n'},{id:26,href:"/docs/reference/multi-account-setups/",title:"Multi-Account Setups",description:"",content:"\u003cp\u003eUnlike the open source LocalStack, which uses a single hardcoded account ID (\u003ccode\u003e000000000000\u003c/code\u003e), the Pro version allows to use multiple instances for different AWS account IDs in parallel.\u003c/p\u003e\n\u003cp\u003eIn order to set up a multi-account environment, simply configure the \u003ccode\u003eTEST_AWS_ACCOUNT_ID\u003c/code\u003e to include a comma-separated list of account IDs. For example, use the following to start up LocalStack with two account IDs:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ TEST_AWS_ACCOUNT_ID=000000000001,000000000002 SERVICES=s3 localstack start\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can then use \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e to address resources in the two separate account instances:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ AWS_ACCESS_KEY_ID=000000000001 aws --endpoint-url=http://localhost:4566 s3 mb s3://bucket-account-one\nmake_bucket: bucket-account-one\n$ AWS_ACCESS_KEY_ID=000000000002 aws --endpoint-url=http://localhost:4566 s3 mb s3://bucket-account-two\nmake_bucket: bucket-account-two\n$ AWS_ACCESS_KEY_ID=000000000001 aws --endpoint-url=http://localhost:4566 s3 ls\n2020-05-24 17:09:41 bucket-account-one\n$ AWS_ACCESS_KEY_ID=000000000002 aws --endpoint-url=http://localhost:4566 s3 ls\n2020-05-24 17:09:53 bucket-account-two\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote that using an invalid account ID should result in a 404 (not found) error response from the API:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ AWS_ACCESS_KEY_ID=123000000123 aws --endpoint-url=http://localhost:4566 s3 ls\nAn error occurred (404) when calling the ListBuckets operation: Not Found\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e For now, the account ID is encoded directly in the \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e client-side variable, for simplicity. In a future version, we will support proper access key IDs issued by the local IAM service, which will then internally be translated to corresponding account IDs.\u003c/p\u003e\n"},{id:27,href:"/docs/reference/multi-region-support/",title:"Multi-Region Support",description:"",content:"\u003cp\u003eWhile the open source version of LocalStack can only be configured to use a single region (e.g., \u003ccode\u003eus-east-1\u003c/code\u003e), the Pro version contains several extensions that allow resources to be addressed across regions, using their unique ARN identifiers.\u003c/p\u003e\n"},{id:28,href:"/docs/reference/neptune/",title:"Amazon Neptune",description:"",content:"\u003cp\u003eThe Neptune API provides a graph database to store nodes and edges that can be accessed via Apache TinkerPop and Gremlin queries.\u003c/p\u003e\n\u003cp\u003eFor example, you can create a Neptune cluster like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport boto3\nfrom gremlin_python.driver import client as gremlin_client\nclient = boto3.client('neptune', endpoint_url='http://localhost:4566')\ncluster = client.create_db_cluster(DBClusterIdentifier='c1', Engine='neptune')['DBCluster']\ncluster_url = 'ws://localhost:%s/gremlin' % cluster['Port']\ngraph_client = gremlin_client.Client(cluster_url, 'g')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u0026hellip; and then submit and query values to the DB like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evalues = '[1,2,3,4]'\nresult_set = graph_client.submit(values)\nresults = result_set.all().result()\nassert results == [1, 2, 3, 4]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor a simple Neptune sample running on LocalStack, please refer to \u003ca href=\"https://github.com/localstack/localstack-pro-samples/tree/master/neptune-graph-db\"\u003ethis Github repository\u003c/a\u003e.\u003c/p\u003e\n"},{id:29,href:"/docs/reference/qldb/",title:"Quantum Ledger Database (QLDB)",description:"",content:"\u003cp\u003eThe Quantum Ledger Database (QLDB) API supports queries over cryptographically verifiable data, stored in a journal of immutable transaction events. LocalStack allows to create local ledgers and journals, to perform \u003ccode\u003eCREATE TABLE\u003c/code\u003e statements, to insert data via \u003ccode\u003eINSERT\u003c/code\u003e statements, and to query data via \u003ccode\u003eSELECT\u003c/code\u003e statements.\u003c/p\u003e\n\u003cp\u003eQLDB uses the \u003ca href=\"https://amzn.github.io/ion-docs\"\u003eAmazon ION data format\u003c/a\u003e, a data serialization format that represents a superset of JSON, with a number of additional features.\u003c/p\u003e\n\u003cp\u003eA simple QLDB example running on LocalStack is provided in \u003ca href=\"https://github.com/localstack/localstack-pro-samples/tree/master/qldb-ledger-queries\"\u003ethis Github repository\u003c/a\u003e. The sample consists of two simple scenarios: (1) to create and list tables via the \u003ccode\u003epyqldb\u003c/code\u003e Python library, and (2) to insert data into two tables and perform a \u003ccode\u003eJOIN\u003c/code\u003e query that combines data from the two tables. The sample output is posted below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eScenario 1: create and list tables in ledger\n-----------\nCreating new test ledger in QLDB API: ledger-test-1\nCreating two test tables in ledger\nRetrieved list of tables in ledger ledger-test-1: ['foobar1', 'foobar2']\n-----------\nScenario 2: create ledger tables and run join query\n-----------\nCreating two test tables in ledger - \u0026quot;Vehicle\u0026quot; and \u0026quot;VehicleRegistration\u0026quot;\nRunning a query that joins data from the two tables\nQuery result: [{'Vehicle': {'id': 'v1'}}, {'Vehicle': {'id': 'v2'}}, {'Vehicle': {'id': 'v3'}}]\n\u003c/code\u003e\u003c/pre\u003e\n"},{id:30,href:"/docs/reference/rds/",title:"Relational Database Service (RDS)",description:"",content:'\u003cp\u003eLocalStack supports a basic version of \u003ca href="https://aws.amazon.com/rds/"\u003eRDS\u003c/a\u003e for testing. Currently, it is possible to spin up PostgreSQL databases on the local machine; support for MySQL and other DB engines is under development and coming soon.\u003c/p\u003e\n\u003cp\u003eThe local RDS service also supports the \u003ca href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html"\u003eRDS Data API\u003c/a\u003e, which allows executing data queries over a JSON/REST interface. Below is a simple example that illustrates (1) creation of an RDS database, (2) creation of a SecretsManager secret with the DB password, and (3) running a simple \u003ccode\u003eSELECT 123\u003c/code\u003e query via the RDS Data API.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal rds create-db-instance --db-instance-identifier db1 --db-instance-class c1 --engine postgres\n...\n$ awslocal secretsmanager create-secret --name dbpass --secret-string test\n{\n    \u0026quot;ARN\u0026quot;: \u0026quot;arn:aws:secretsmanager:eu-central-1:1234567890㊙️dbpass-cfnAX\u0026quot;,\n    \u0026quot;Name\u0026quot;: \u0026quot;dbpass\u0026quot;,\n    \u0026quot;VersionId\u0026quot;: \u0026quot;fffa1f4a-2381-4a2b-a977-4869d59a16c0\u0026quot;\n}\n$ awslocal rds-data execute-statement --database test --resource-arn arn:aws:rds:eu-central-1:000000000000:db:db1 --secret-arn arn:aws:secretsmanager:eu-central-1:1234567890㊙️dbpass-cfnAX --sql \'SELECT 123\'\n{\n    \u0026quot;columnMetadata\u0026quot;: [{\n        \u0026quot;name\u0026quot;: \u0026quot;?column?\u0026quot;,\n        \u0026quot;type\u0026quot;: 23\n    }],\n    \u0026quot;records\u0026quot;: [[\n        { \u0026quot;doubleValue\u0026quot;: 123 }\n    ]]\n}\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:31,href:"/docs/reference/route53/",title:"Route 53",description:"",content:"\u003cp\u003eThe Route53 API in LocalStack Pro allows you to create hosted zones and to manage DNS entries (e.g., A records) which can then be queried via the built-in DNS server.\u003c/p\u003e\n\u003cp\u003eThe example below illustrates the creation of a hosted zone \u003ccode\u003eexample.com\u003c/code\u003e, registration of an A record named \u003ccode\u003etest.example.com\u003c/code\u003e that points to \u003ccode\u003e1.2.3.4\u003c/code\u003e, and finally querying the DNS record by using the \u003ccode\u003edig\u003c/code\u003e command against the DNS server running on \u003ccode\u003elocalhost\u003c/code\u003e (inside the LocalStack container, on port \u003ccode\u003e53\u003c/code\u003e):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ zone_id=$(awslocal route53 create-hosted-zone --name example.com --caller-reference r1 | jq -r '.HostedZone.Id')\n$ awslocal route53 change-resource-record-sets --hosted-zone-id $zone_id --change-batch 'Changes=[{Action=CREATE,ResourceRecordSet={Name=test.example.com,Type=A,ResourceRecords=[{Value=1.2.3.4}]}}]'\n$ dig @localhost test.example.com\n...\n;; ANSWER SECTION:\ntest.example.com.	300	IN	A	1.2.3.4\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: Using the built-in DNS capabilities requires privileged access for the LocalStack container (please also refer to the \u003ccode\u003eDNS_ADDRESS\u003c/code\u003e configuration variable).\u003c/p\u003e\n"},{id:32,href:"/docs/reference/sagemaker/",title:"SageMaker",description:"",content:"\u003cp\u003eLocalStack Pro provides a local version of the SageMaker API, which allows running jobs to create machine learning models (e.g., using TensorFlow).\u003c/p\u003e\n\u003cp\u003eA basic example using the \u003ccode\u003esagemaker.tensorflow.TensorFlow\u003c/code\u003e class is provided in \u003ca href=\"https://github.com/localstack/localstack-pro-samples/tree/master/sagemaker-ml-jobs\"\u003ethis Github repository\u003c/a\u003e. Essentially, the code boils down to these core lines:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003einputs = ...  # load training data files\nmnist_estimator = TensorFlow(entry_point='mnist.py', role='arn:aws:...',\n    framework_version='1.12.0', sagemaker_session=sagemaker_session,\n    train_instance_count=1, training_steps=10, evaluation_steps=10)\nmnist_estimator.fit(inputs, logs=False)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe code snippet above uploads the model training code to local S3, submits a new training job to the local SageMaker API, and finally puts the trained model back to an output S3 bucket. Please refer to the sample repo for more details.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e SageMaker is a fairly comprehensive API - for now, only a subset of the functionality is provided locally, but new features are being added on a regular basis.\u003c/p\u003e\n"},{id:33,href:"/docs/reference/ses/",title:"Simple Email Service (SES)",description:"",content:'\u003cp\u003eThe Pro version ships with extended support Simple Email Service (SES), including a simple user interface to inspect email accounts and sent messages, as well as support for sending SES messages through an actual SMTP email server.\u003c/p\u003e\n\u003cp\u003ePlease refer to the \u003ca href="#configuration"\u003eConfiguration section\u003c/a\u003e for instructions on how to configure the connection parameters of your SMTP server (\u003ccode\u003eSMTP_HOST\u003c/code\u003e/\u003ccode\u003eSMTP_USER\u003c/code\u003e/\u003ccode\u003eSMTP_PASS\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eOnce your SMTP server has been configured, you can use the SES user interface in the Web app to create a new email account (e.g., \u003ccode\u003euser1@yourdomain.com\u003c/code\u003e), and then send an email via the command line (or your SES client SDK):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ awslocal ses send-email --from user1@yourdomain.com --message \'Body={Text={Data=\u0026quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit, ...\u0026quot;}},Subject={Data=Test Email}\' --destination \'ToAddresses=recipient1@example.com\'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ca href="https://app.localstack.cloud"\u003eWeb user interface\u003c/a\u003e then allows you to interactively browse through the sent email messages, as illustrated in the screenshot below:\u003c/p\u003e\n\u003cimg class="img-simple img-fluid lazyload blur-up" src="/docs/reference/ses/sesInterface_hu0fbfbf07682887d84dfb50160947cfbe_244162_20x0_resize_box_2.png" data-src="/docs/reference/ses/sesInterface.png" width="2260" height="932" alt="SES Web Interface"\u003e\n'},{id:34,href:"/docs/reference/test-report-dashboards/",title:"Test Report Dashboards",description:"",content:"\u003cp\u003eLocalStack allows for transparent collection of execution events, in order to provide usage analytics and insights into the testing process overall. Simply configure your system with the \u003ccode\u003eLOCALSTACK_API_KEY\u003c/code\u003e environment variable, and the system will start making your events accessible on the LocalStack dashboard at https://app.localstack.cloud/dashboard.\u003c/p\u003e\n\u003cp\u003ePlease note that data privacy is one of our key concerns; data is only collected in an anonymized way, and never exposes any sensitive information about your application.\u003c/p\u003e\n"},{id:35,href:"/docs/reference/transfer/",title:"Transfer",description:"",content:'\u003cp\u003eThe AWS Transfer API provides the ability to create FTP(S) servers to make files in S3 buckets accessible directly via FTP.\u003c/p\u003e\n\u003cp\u003eA simple example using AWS Transfer is included in \u003ca href="https://github.com/localstack/localstack-pro-samples/tree/master/transfer-ftp-s3"\u003ethis Github repository\u003c/a\u003e. The sample creates an FTP server via the Transfer API locally, uploads two files via FTP to S3, and then finally downloads the files from the target S3 bucket.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e The Transfer API does not provide a way to return the endpoint URL of created FTP servers. Hence, in order to determine the server endpoint, the local port is encoded as a suffix in the \u003ccode\u003eServerId\u003c/code\u003e attribute, using the pattern \u003ccode\u003es-\u0026lt;id\u0026gt;:\u0026lt;port\u0026gt;\u003c/code\u003e. For example, assume the following is the response from the \u003ccode\u003eCreateServer\u003c/code\u003e API call, then the FTP server is accessible on port \u003ccode\u003e4511\u003c/code\u003e (i.e., \u003ccode\u003eftp://localhost:4511\u003c/code\u003e):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \u0026quot;ServerId\u0026quot;: \u0026quot;s-73c53daf86da4:4511\u0026quot;\n}\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:36,href:"/docs/reference/xray-tracing/",title:"XRay Tracing",description:"",content:"\u003cp\u003eLocalStack Pro allows to instrument your applications using \u003ca href=\"https://aws.amazon.com/xray/\"\u003eXRay\u003c/a\u003e tracing. This helps in optimizing the interactions between service calls, and facilitates debugging of performance bottlenecks.\u003c/p\u003e\n\u003cp\u003eFor example, a Python Lambda function can be instrumented as follows (based on the example \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/python-tracing.html\"\u003ehere\u003c/a\u003e):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport boto3\nfrom aws_xray_sdk.core import xray_recorder\nfrom aws_xray_sdk.core import patch\npatch(['boto3'])\ns3_client = boto3.client('s3')\n\ndef lambda_handler(event, context):\n    s3_client.create_bucket(Bucket='mybucket')\n    xray_recorder.begin_subsegment('my_code')\n    # your function code goes here...\n    xray_recorder.end_subsegment()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRunning this code in Lambda on LocalStack will result in two trace segments being created in XRay - one from the instrumented \u003ccode\u003eboto3\u003c/code\u003e client when running \u003ccode\u003ecreate_bucket(..)\u003c/code\u003e, and one for the custom subsegment denoted \u003ccode\u003e'my_code'\u003c/code\u003e. You can use the regular XRay API calls (e.g., \u003ca href=\"https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html\"\u003e\u003ccode\u003eGetTraceSummaries\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html\"\u003e\u003ccode\u003eBatchGetTraces\u003c/code\u003e\u003c/a\u003e) to retrieve the details (timestamps, IDs, etc) of these segments.\u003c/p\u003e\n"},{id:37,href:"/docs/help/troubleshooting/",title:"Troubleshooting",description:"Solutions to common problems.",content:'\u003ch2 id="common-issues"\u003eCommon issues\u003c/h2\u003e\n\u003cp\u003eThis section contains a number of common known issues and solutions to fix them.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eIf you get an error \u003ccode\u003eproxy: listen udp 0.0.0.0:53: bind: address already in use.\u003c/code\u003e when trying to start the Docker container, there is likely another DNS server already running on your machine. You can configure the \u003ccode\u003eDNS_ADDRESS\u003c/code\u003e environment variable to bind the DNS server to any IP address that does not conflict with the local setup (e.g., \u003ccode\u003eDNS_ADDRESS=22.22.22.22\u003c/code\u003e, or \u003ccode\u003eDNS_ADDRESS=0\u003c/code\u003e to disable the DNS server port entirely).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you get an error \u003ccode\u003eImportError: cannot import name requests\u003c/code\u003e (or similar) on \u003ccode\u003epip install localstack\u003c/code\u003e, you may have to downgrade your version of \u003ccode\u003epip\u003c/code\u003e to \u003ccode\u003e9.x.x\u003c/code\u003e, e.g., \u003ccode\u003epip install --upgrade pip==9.0.3\u003c/code\u003e. See \u003ca href="https://stackoverflow.com/a/50991067/5265979"\u003ehere\u003c/a\u003e for reference.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf \u003ccode\u003epip install ...\u003c/code\u003e fails with an error like the one below, try installing YAML development libs (e.g., \u003ccode\u003ebrew install libyaml\u003c/code\u003e under Mac OS).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e#include \u0026lt;yaml.h\u0026gt;\n         ^~~~~~~~\n1 error generated.\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:38,href:"/docs/help/support/",title:"Support",description:"Get support for LocalStack.",content:'\u003ch2 id="support"\u003eSupport\u003c/h2\u003e\n\u003cp\u003eFor any technical enquiries or questions regarding usage of LocalStack itself, the best resource is usually to search the \u003ca href="https://github.com/localstack/localstack/issues"\u003elist of issues\u003c/a\u003e in the Github repository. In many cases, it is easy to find a solution using the issue search function on Github. Otherwise, please raise a new issue on Github with a detailed error description.\u003c/p\u003e\n\u003ch2 id="deviations-from-aws-apis"\u003eDeviations From AWS APIs\u003c/h2\u003e\n\u003cp\u003eThe AWS cloud is a very dynamic environment with constant extension and improvement of APIs. Due to the sheer size and complexity of the AWS environment, we cannot guarantee 100% compatibility with all APIs at all times. Occasionally, the behavior of the LocalStack APIs may slightly deviate from AWS, although in general we try to ensure that the core functionality has high level of compatibility.\u003c/p\u003e\n\u003ch2 id="bug-reports"\u003eBug Reports\u003c/h2\u003e\n\u003cp\u003eAs in any other software product, the user may occasionally run into errors reported by the platform. Some issues are caused by invalid or unexpected input values from the user\u0026rsquo;s applications, some are caused by a flaw in the internal implementation. We are working very hard to fix bugs in a timely manner and maintain a high level of quality of the platform.\u003c/p\u003e\n\u003cp\u003eWhen creating issues and bug reports, please make sure to include a detailed description of the error (including debug logs, error messages, etc), as well as information about the environment in which the error has occurred.\u003c/p\u003e\n\u003cp\u003eRequests are processed on a best-effort basis. Depending on your level of support, we may be able (but cannot guarantee) to prioritize your support requests.\u003c/p\u003e\n\u003ch2 id="general-enquiries"\u003eGeneral Enquiries\u003c/h2\u003e\n\u003cp\u003eFor enquiries regarding billing, subscriptions, or other administrative issues, please send us an email to \u003ca href="info@localstack.cloud"\u003einfo@localstack.cloud\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id="community-vs-pro-edition"\u003eCommunity vs Pro Edition\u003c/h2\u003e\n\u003cp\u003eA free edition of LocalStack is provided as an open source \u003ca href="https://github.com/localstack/localstack"\u003eproject on Github\u003c/a\u003e. The free edition has a limited feature set, and lacks any enterprise features like dashboarding, analytics, or customer support.\u003c/p\u003e\n'},{id:39,href:"/docs/help/",title:"Help",description:"Get help with LocalStack.",content:""},{id:40,href:"/docs/",title:"Docs",description:"Docs Doks.",content:""},{id:41,href:"/docs/getting-started/",title:"Getting Started",description:"",content:""},{id:42,href:"/docs/how-to/",title:"How-to Guides",description:"",content:""},{id:43,href:"/docs/reference/",title:"Reference",description:"LocalStack Reference Documentation",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()}referenceChildren=document.getElementById('Reference-children'),referenceChildren!=null&&(referenceCollapseBtn=document.getElementById('Reference-btn'),referenceChildren.addEventListener('hide.bs.collapse',function(){const a=referenceCollapseBtn.getElementsByTagName('i')[0];a.classList.add('bi-chevron-compact-left'),a.classList.remove('bi-chevron-compact-down')}),referenceChildren.addEventListener('show.bs.collapse',function(){const a=referenceCollapseBtn.getElementsByTagName('i')[0];a.classList.add('bi-chevron-compact-down'),a.classList.remove('bi-chevron-compact-left')}))